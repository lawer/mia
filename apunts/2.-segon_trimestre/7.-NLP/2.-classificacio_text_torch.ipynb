{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "188b48ed5b49e64b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classificador de notícies\n",
    "\n",
    "En aquesta pràctica, crearem un classificador de notícies utilitzant les tècniques de processament de llenguatge natural que hem vist a classe, centrades en la representació del text.\n",
    "\n",
    "Utilitzarem el `dataset` [AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset) que conté 1.000.000 de notícies de 4 categories diferents.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Per carregar el dataset, utilitzarem la llibreria `datasets`. Aquesta llibreria ens permetrà carregar molts datasets diferents de manera senzilla. En aquest cas, carregarem el dataset d'AG News."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a731df9a4a91fd19",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparació del dataset\n",
    "\n",
    "Per instal·lar les llibreries necessàries, executarem la següent cel·la. \n",
    "\n",
    "Anem a utilitzar `pytorch` (una llibreria de deep learning), `pipeline` (una llibreria de tractament de dades), `scikit-learn` (una llibreria de machine learning) i `transformers` (una llibreria de models de llenguatge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9987ceaeb8f560be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:06:47.825392Z",
     "start_time": "2024-01-17T21:06:09.205588Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: scikit-learn in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: transformers in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (4.48.2)\n",
      "Requirement already satisfied: filelock in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (0.24.6)\n",
      "Requirement already satisfied: packaging in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instalem les llibreries necessàries en les versions correctes\n",
    "\n",
    "!pip install torch datasets scikit-learn transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b60a6618dbd12a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:07:05.113346Z",
     "start_time": "2024-01-17T21:06:47.834079Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Carreguem el dataset. Es descarregarà automàticament i es guardarà en local. \n",
    "# Aquest dataset conté notícies de diferents categories. En aquest cas\n",
    "# utilitzarem les categories World, Sports, Business i Sci/Tech.\n",
    "\n",
    "dataset = load_dataset('ag_news')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e10ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n",
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['World', 'Sports', 'Business', 'Sci/Tech'], id=None)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['World', 'Sports', 'Business', 'Sci/Tech']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset['train'][0])\n",
    "\n",
    "print(dataset['train'].features)\n",
    "\n",
    "classes = dataset['train'].features[\"label\"].names\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba463cc1c41c1298",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Automáticament, la funció `load` ha dividit el dataset en dos conjunts: un de train i un de test. Per accedir a aquests conjunts, utilitzarem els atributs `train` i `test` de l'objecte `dataset`. Aquests atributs són objectes `tf.data.Dataset` que contenen els exemples i les etiquetes del conjunt d'entrenament i de test. Per accedir als exemples i les etiquetes, utilitzarem els atributs `data` i `label` de l'objecte `tf.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca34052cf84fbd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:07:05.194181Z",
     "start_time": "2024-01-17T21:07:05.122941Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples de train: 120000\n",
      "Nombre d'exemples de test: 7600\n"
     ]
    }
   ],
   "source": [
    "# Separem el dataset en conjunt d'entrenament i de test\n",
    "ds_train = dataset['train']\n",
    "ds_test = dataset['test']\n",
    "# Vejam quants exemples hi ha en cada conjunt\n",
    "print('Nombre d\\'exemples de train:', len(ds_train))\n",
    "print('Nombre d\\'exemples de test:', len(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3645de832fbdacf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Imprimim els primers 5 exemples del conjunt d'entrenament. Com podem veure, cada exemple és una notícia i la seva etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e7bededaa593f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:07:05.480814Z",
     "start_time": "2024-01-17T21:07:05.152188Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (Business) -> Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "2 (Business) -> Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n",
      "2 (Business) -> Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
      "2 (Business) -> Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\n",
      "2 (Business) -> Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\n"
     ]
    }
   ],
   "source": [
    "# Imprimim els primers 5 exemples del conjunt d'entrenament\n",
    "for w in ds_train.take(5):\n",
    "    print(f\"{w['label']} ({classes[w['label']]}) -> {w['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e77e47",
   "metadata": {},
   "source": [
    "## Tokenització\n",
    "\n",
    "La representació del text en un model de llenguatge requereix que el text sigui convertit en números. Si volem una representació a nivell de paraula, necessitem fer dues coses:\n",
    "\n",
    "* Utilitzar un **tokenitzador** per dividir el text en **tokens**.\n",
    "* Construir un **vocabulari** amb aquests tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f8c05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carles/Documentos/notebooks/.venv/lib64/python3.11/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '-', 'hello', ',', 'how', 'are', 'you', 'doing', 'today', '?']\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "# Utilitzem el tokenitzador de BERT (un dels primers models de llenguatge basats en transformers) per tokenitzar les frases\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "print(tokenizer.tokenize(\"-- Hello, how are you doing today?\"))\n",
    "\n",
    "# Podem veure el vocabulari del tokenitzador\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6424e",
   "metadata": {},
   "source": [
    "Utilitzant el tokenitzador, podem també convertir la nostra cadena tokenitzada en un conjunt de números:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169e003b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1011, 1011, 7592, 1010, 2129, 2024, 2017, 2725, 2651, 1029]\n"
     ]
    }
   ],
   "source": [
    "tokenitzada = tokenizer.tokenize(\"-- Hello, how are you doing today?\")\n",
    "\n",
    "def encode(text):\n",
    "    tk = tokenizer.tokenize(text)\n",
    "    return tokenizer.convert_tokens_to_ids(tk)\n",
    "\n",
    "print(encode(\"-- Hello, how are you doing today?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990e6d999d35898",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Representació del text\n",
    "\n",
    "Per poder entrenar un model de xarxes neuronals, necessitem representar el text com a vectors de nombres. En aquesta pràctica, utilitzarem la representació Bag-of-Words (BoW) que consisteix en representar cada paraula com un nombre. Aquesta representació és molt senzilla i no té en compte l'ordre de les paraules ni la seva semàntica. Però és una representació que funciona prou bé en molts casos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89259e6a26a7e3ac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Representació Bag-of-Words\n",
    "\n",
    "Encara que el significat de les paraules no és fàcil de deduir sense poder accedir al context, en alguns casos, la representació Bag-of-Words pot ser útil. Per exemple, en el text d'una notícia, la paraula `covid` pot ser un bon indicador que la notícia parla sobre la pandèmia de la COVID-19 i la paraula `snow` pot ser un bon indicador que la notícia parla sobre el temps atmosfèric.\n",
    "\n",
    "De les tècniques clàssiques de vectorització de text, la més senzilla és la representació Bag-of-Words (BoW). En aquesta representació, cada paraula es representa com un nombre. Per convertir un text en una representació BoW, primer creem un vector amb tants zeros com paraules hi ha en el vocabulari. Després, per cada paraula del text, incrementem en 1 el valor de la posició corresponent al vector. Per exemple, si el text és `this sentence is a test sentence`, el vector resultant seria `[1, 2, 1, 1, 0, 0, 0, 0, 0, 0, ...]`.\n",
    "\n",
    "Si recordem la representació one-hot, veurem que la representació BoW és molt similar. La diferència és que la representació one-hot serà una sèrie de vectors amb un sol 1 i la resta de valors a 0. En canvi, la representació BoW serà un vector amb tants 1 com vegades apareixi cada paraula. Podem considerar que la representació BoW seria la suma de vectors one-hot.\n",
    "\n",
    "Per exemple, si el text és `this sentence is a test sentence`, el vector one-hot de la primera paraula seria `[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]` i el vector one-hot de la segona paraula seria `[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...]`. La representació BoW seria la suma d'aquests dos vectors: `[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...]`.\n",
    "\n",
    "Per generar una representació BoW, utilitzarem aquesta tècnica per convertir cada paraula en un vector one-hot i després sumarem tots els vectors. Per fer-ho, utilitzarem la funció `to_bow` que crearem a continuació. Aquesta funció rep un text i retorna un vector amb la representació BoW del text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d57f10bba32951f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:07:07.472087Z",
     "start_time": "2024-01-17T21:07:07.133342Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 2, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = [\n",
    "        'I like hot dogs.',\n",
    "        'The dog ran fast.',\n",
    "        'Its hot outside.',\n",
    "    ]\n",
    "vectorizer.fit_transform(corpus)\n",
    "\n",
    "vectorizer.transform(['My dog likes hot dogs on a hot day.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ad0ef",
   "metadata": {},
   "source": [
    "Per a calcular el vector BoW de d'una noticia del nostre dataset AG_NEWS, podem utilitzar la següent funció:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7990a193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "len_vocab = len(vocab)\n",
    "\n",
    "def to_bow(text, tamany_vocabulari=len_vocab):\n",
    "    res = torch.zeros(tamany_vocabulari, dtype=torch.float32)\n",
    "\n",
    "    for i in encode(text):\n",
    "        if i<tamany_vocabulari:\n",
    "            res[i] += 1\n",
    "    return res\n",
    "\n",
    "print(ds_train[0])\n",
    "print(to_bow(ds_train[0][\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83bb2a026a54a15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Entrenament del model de classificació BoW\n",
    "\n",
    "El nostre primer model serà un classificador de notícies utilitzant la representació BoW. Per fer-ho, crearem un model de xarxes neuronals amb una capa d'entrada amb tants neurones com paraules hi hagi al nostre vocabulari i una capa de sortida amb tants neurones com categories hi hagi al nostre dataset.\n",
    "\n",
    "#### Representació BoW\n",
    "\n",
    "En primer lloc necessitem convertir el text en la representació BoW utilitzant la funció `to_bow` que hem creat abans. Aquesta funció rep un text i retorna un vector amb la representació BoW del text.\n",
    "\n",
    "En pytorch s'utilitzen els `DataLoaders`, per carregar les dades en lots i convertir-les en tensors de PyTorch. Aprofitarem aquesta funcionalitat per convertir les dades en BoW en tensors de PyTorch, utilitzant el paràmetre `collate_fn` del `DataLoader` i proporcionant una funció que converteixi les dades textuals en tensors de BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd6b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# this collate function gets list of batch_size tuples, and needs to\n",
    "# return a pair of label-feature tensors for the whole minibatch\n",
    "def bowify(batch):\n",
    "    \"\"\"\n",
    "    Aquesta funció rep una llista de noticies i retorna un tensor amb les etiquetes\n",
    "    (vector de floats) i un altre amb les notícies codificades com a BoW (matriu de floats on cada fila\n",
    "    és un vector de BoW).\n",
    "    \"\"\"\n",
    "\n",
    "    # Els labels són 0, 1, 2 o 3.\n",
    "    # Utilitzem LongTensor perquè són enters.\n",
    "\n",
    "    etiquetes = torch.LongTensor([noticia[\"label\"] for noticia in batch])\n",
    "\n",
    "    # Les notícies són tensors de BoW\n",
    "    noticies = torch.stack([to_bow(noticia[\"text\"]) for noticia in batch])\n",
    "\n",
    "    return (etiquetes, noticies)\n",
    "\n",
    "train_loader = DataLoader(ds_train, batch_size=16, collate_fn=bowify)\n",
    "test_loader = DataLoader(ds_test, batch_size=16, collate_fn=bowify)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85d6ad8ccb956f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model de classificació\n",
    "\n",
    "Now let's define a simple classifier neural network that contains one linear layer. The size of the input vector equals to `vocab_size`, and output size corresponds to the number of classes (4). Because we are solving classification task, the final activation function is `LogSoftmax()`.\n",
    "\n",
    "Ara crearem el model de classificació utilitzant PyTorch. Definirem un model senzill amb una capa lineal. La mida del vector d'entrada serà `vocab_size` i la mida de la sortida serà el nombre de classes (4). Com que estem resolent una tasca de classificació, la funció d'activació final serà `LogSoftmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f785d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(len(vocab), 4),\n",
    "    torch.nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "# També podem definir la xarxa neuronal com a classe\n",
    "\n",
    "class BoWClassifier(torch.nn.Module):\n",
    "    def __init__(self, tamany_vocabulari, num_classes):\n",
    "        # En el constructor definim les capes de la xarxa\n",
    "        # crida al constructor de la classe pare\n",
    "        super().__init__()\n",
    "\n",
    "        # Capa lineal que passa de tamany_vocabulari a num_classes\n",
    "        self.fc = torch.nn.Linear(tamany_vocabulari, num_classes)\n",
    "\n",
    "        # Funció de softmax per obtenir probabilitats\n",
    "        self.logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "        # Com a funció de pèrdua utilitzarem la NNLLLoss (Negative Log Likelihood Loss)\n",
    "        # S'utilitza per classificació multiclasse i determina la pèrdua entre les prediccions\n",
    "        # i les etiquetes\n",
    "\n",
    "        self.loss = torch.nn.NLLLoss()\n",
    "\n",
    "    def forward(self, ids):\n",
    "        # x és el vector de BoW de la notícia\n",
    "        # labels és l'etiqueta de la notícia\n",
    "\n",
    "        # Passem x per la capa lineal\n",
    "        ids = self.fc(ids)\n",
    "        \n",
    "        # Passem x per la funció de softmax\n",
    "        ids = self.logsoftmax(ids)\n",
    "\n",
    "        return ids\n",
    "    \n",
    "net = BoWClassifier(len(vocab), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d5e68",
   "metadata": {},
   "source": [
    "### Entrenament del model\n",
    "\n",
    "Ara definirem el bucle d'entrenament estàndard de PyTorch. Com que el nostre dataset és bastant gran, per a la nostra finalitat docent entrenarem només per una època, i a vegades fins i tot per menys d'una època (especificant el paràmetre `epoch_size` ens permet limitar l'entrenament). També informarem de l'exactitud d'entrenament acumulada durant l'entrenament; la freqüència de notificació es especifica utilitzant el paràmetre `report_freq`.\n",
    "\n",
    "Per entrenar el model, utilitzarem l'optimitzador `Adam` (ja que és un dels optimitzadors més utilitzats) i la funció de cost `CrossEntropyLoss` (ja que tenim un problema de classificació amb més de dues classes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e46fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "3200: acc=0.7396875\n",
      "6400: acc=0.8034375\n",
      "9600: acc=0.8259375\n",
      "12800: acc=0.841328125\n",
      "16000: acc=0.8498125\n",
      "19200: acc=0.8546354166666666\n",
      "22400: acc=0.8602232142857142\n",
      "25600: acc=0.8644140625\n",
      "28800: acc=0.8658680555555556\n",
      "32000: acc=0.86778125\n",
      "35200: acc=0.8705113636363636\n",
      "38400: acc=0.872109375\n",
      "41600: acc=0.8735576923076923\n",
      "44800: acc=0.8751116071428572\n",
      "48000: acc=0.8755833333333334\n",
      "51200: acc=0.8759765625\n",
      "54400: acc=0.8772242647058823\n",
      "57600: acc=0.8780381944444444\n",
      "60800: acc=0.8776809210526316\n",
      "64000: acc=0.8778125\n",
      "67200: acc=0.8787946428571428\n",
      "70400: acc=0.8792897727272727\n",
      "73600: acc=0.88\n",
      "76800: acc=0.8814713541666667\n",
      "80000: acc=0.8832375\n",
      "83200: acc=0.8846514423076923\n",
      "86400: acc=0.8849537037037037\n",
      "89600: acc=0.8851674107142857\n",
      "92800: acc=0.8859051724137931\n",
      "96000: acc=0.88640625\n",
      "99200: acc=0.886633064516129\n",
      "102400: acc=0.886943359375\n",
      "105600: acc=0.887717803030303\n",
      "108800: acc=0.8881341911764706\n",
      "112000: acc=0.8883660714285714\n",
      "115200: acc=0.888984375\n",
      "118400: acc=0.8894763513513514\n",
      "Train loss: 0.026074605305989585, Train acc: 0.8898833333333334\n",
      "Epoch 1\n",
      "3200: acc=0.859375\n",
      "6400: acc=0.8725\n",
      "9600: acc=0.8798958333333333\n",
      "12800: acc=0.88828125\n",
      "16000: acc=0.8930625\n",
      "19200: acc=0.8964583333333334\n",
      "22400: acc=0.9000446428571428\n",
      "25600: acc=0.903203125\n",
      "28800: acc=0.9035069444444445\n",
      "32000: acc=0.90521875\n",
      "35200: acc=0.9067329545454546\n",
      "38400: acc=0.9075520833333334\n",
      "41600: acc=0.9085336538461538\n",
      "44800: acc=0.9093303571428571\n",
      "48000: acc=0.9098333333333334\n",
      "51200: acc=0.91056640625\n",
      "54400: acc=0.9111580882352941\n",
      "57600: acc=0.9116319444444444\n",
      "60800: acc=0.9111184210526316\n",
      "64000: acc=0.911203125\n",
      "67200: acc=0.9121428571428571\n",
      "70400: acc=0.912784090909091\n",
      "73600: acc=0.9131521739130435\n",
      "76800: acc=0.9142317708333333\n",
      "80000: acc=0.9154375\n",
      "83200: acc=0.9163221153846154\n",
      "86400: acc=0.916724537037037\n",
      "89600: acc=0.9168080357142857\n",
      "92800: acc=0.9171982758620689\n",
      "96000: acc=0.9176354166666667\n",
      "99200: acc=0.9178024193548387\n",
      "102400: acc=0.91806640625\n",
      "105600: acc=0.9185606060606061\n",
      "108800: acc=0.9188970588235295\n",
      "112000: acc=0.9189732142857143\n",
      "115200: acc=0.9193402777777778\n",
      "118400: acc=0.9195777027027027\n",
      "Train loss: 0.020352254231770832, Train acc: 0.9198333333333333\n",
      "Epoch 2\n",
      "3200: acc=0.8934375\n",
      "6400: acc=0.90328125\n",
      "9600: acc=0.9061458333333333\n",
      "12800: acc=0.9125\n",
      "16000: acc=0.915375\n",
      "19200: acc=0.91828125\n",
      "22400: acc=0.9206696428571428\n",
      "25600: acc=0.9231640625\n",
      "28800: acc=0.9227777777777778\n",
      "32000: acc=0.9241875\n",
      "35200: acc=0.9251704545454545\n",
      "38400: acc=0.925859375\n",
      "41600: acc=0.9266346153846153\n",
      "44800: acc=0.9271428571428572\n",
      "48000: acc=0.92725\n",
      "51200: acc=0.927421875\n",
      "54400: acc=0.9279411764705883\n",
      "57600: acc=0.9283333333333333\n",
      "60800: acc=0.9277467105263157\n",
      "64000: acc=0.927671875\n",
      "67200: acc=0.9284077380952381\n",
      "70400: acc=0.9288920454545454\n",
      "73600: acc=0.9290625\n",
      "76800: acc=0.9299479166666667\n",
      "80000: acc=0.93105\n",
      "83200: acc=0.9319350961538462\n",
      "86400: acc=0.9324652777777778\n",
      "89600: acc=0.9327232142857143\n",
      "92800: acc=0.9331788793103448\n",
      "96000: acc=0.9332708333333334\n",
      "99200: acc=0.9333467741935484\n",
      "102400: acc=0.933525390625\n",
      "105600: acc=0.933967803030303\n",
      "108800: acc=0.9340992647058823\n",
      "112000: acc=0.9340714285714286\n",
      "115200: acc=0.93421875\n",
      "118400: acc=0.9343158783783784\n",
      "Train loss: 0.016947901407877605, Train acc: 0.934425\n",
      "Epoch 3\n",
      "3200: acc=0.9171875\n",
      "6400: acc=0.9221875\n",
      "9600: acc=0.9230208333333333\n",
      "12800: acc=0.92703125\n",
      "16000: acc=0.92975\n",
      "19200: acc=0.9308333333333333\n",
      "22400: acc=0.9330803571428572\n",
      "25600: acc=0.9349609375\n",
      "28800: acc=0.9342361111111112\n",
      "32000: acc=0.93534375\n",
      "35200: acc=0.9361079545454546\n",
      "38400: acc=0.9362760416666667\n",
      "41600: acc=0.9369471153846154\n",
      "44800: acc=0.9370982142857143\n",
      "48000: acc=0.9372083333333333\n",
      "51200: acc=0.937578125\n",
      "54400: acc=0.9380514705882353\n",
      "57600: acc=0.9384548611111111\n",
      "60800: acc=0.9379934210526316\n",
      "64000: acc=0.93803125\n",
      "67200: acc=0.9385565476190476\n",
      "70400: acc=0.9390482954545455\n",
      "73600: acc=0.9391304347826087\n",
      "76800: acc=0.9397135416666667\n",
      "80000: acc=0.940675\n",
      "83200: acc=0.9414903846153846\n",
      "86400: acc=0.941863425925926\n",
      "89600: acc=0.9419754464285715\n",
      "92800: acc=0.9423383620689655\n",
      "96000: acc=0.9424583333333333\n",
      "99200: acc=0.9425907258064516\n",
      "102400: acc=0.942734375\n",
      "105600: acc=0.9431439393939394\n",
      "108800: acc=0.9431158088235294\n",
      "112000: acc=0.9429821428571429\n",
      "115200: acc=0.9430729166666667\n",
      "118400: acc=0.943133445945946\n",
      "Train loss: 0.014687940470377605, Train acc: 0.9432916666666666\n",
      "Epoch 4\n",
      "3200: acc=0.9290625\n",
      "6400: acc=0.93484375\n",
      "9600: acc=0.9344791666666666\n",
      "12800: acc=0.93734375\n",
      "16000: acc=0.939625\n",
      "19200: acc=0.9408854166666667\n",
      "22400: acc=0.9431696428571429\n",
      "25600: acc=0.9444921875\n",
      "28800: acc=0.9435763888888888\n",
      "32000: acc=0.94440625\n",
      "35200: acc=0.9445738636363636\n",
      "38400: acc=0.944765625\n",
      "41600: acc=0.9452884615384616\n",
      "44800: acc=0.9455803571428572\n",
      "48000: acc=0.9455833333333333\n",
      "51200: acc=0.94607421875\n",
      "54400: acc=0.9463602941176471\n",
      "57600: acc=0.9465451388888889\n",
      "60800: acc=0.9461513157894736\n",
      "64000: acc=0.946046875\n",
      "67200: acc=0.9464285714285714\n",
      "70400: acc=0.946846590909091\n",
      "73600: acc=0.9469836956521739\n",
      "76800: acc=0.9475911458333334\n",
      "80000: acc=0.9484625\n",
      "83200: acc=0.9491346153846154\n",
      "86400: acc=0.9492939814814815\n",
      "89600: acc=0.9494084821428571\n",
      "92800: acc=0.9497521551724138\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 77\u001b[0m\n\u001b[1;32m     72\u001b[0m         train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_epoch(\n\u001b[1;32m     73\u001b[0m             net, train_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer, report_freq\u001b[38;5;241m=\u001b[39mreport_freq\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 72\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, test_loader, lr, epochs, report_freq)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_freq\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(net, dataloader, lr, optimizer, loss_fn, epoch_size, report_freq)\u001b[0m\n\u001b[1;32m     17\u001b[0m total_loss, acc, count, i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Iterem sobre el dataloader\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Posem els gradients a zero\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Calculem la sortida de la xarxa\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Documentos/notebooks/.venv/lib64/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/Documentos/notebooks/.venv/lib64/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documentos/notebooks/.venv/lib64/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m, in \u001b[0;36mbowify\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m etiquetes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor([noticia[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m noticia \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Les notícies són tensors de BoW\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m noticies \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[43m[\u001b[49m\u001b[43mto_bow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoticia\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnoticia\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (etiquetes, noticies)\n",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m etiquetes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor([noticia[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m noticia \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Les notícies són tensors de BoW\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m noticies \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mto_bow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoticia\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m noticia \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (etiquetes, noticies)\n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mto_bow\u001b[0;34m(text, tamany_vocabulari)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_bow\u001b[39m(text, tamany_vocabulari\u001b[38;5;241m=\u001b[39mlen_vocab):\n\u001b[1;32m      6\u001b[0m     res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(tamany_vocabulari, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m<\u001b[39mtamany_vocabulari:\n\u001b[1;32m     10\u001b[0m             res[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(text):\n\u001b[0;32m----> 4\u001b[0m     tk \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tk)\n",
      "File \u001b[0;32m~/Documentos/notebooks/.venv/lib64/python3.11/site-packages/transformers/tokenization_utils.py:698\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    699\u001b[0m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[0;32m~/Documentos/notebooks/.venv/lib64/python3.11/site-packages/transformers/models/bert/tokenization_bert.py:168\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[0;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[1;32m    166\u001b[0m             split_tokens\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m             split_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwordpiece_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     split_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwordpiece_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/Documentos/notebooks/.venv/lib64/python3.11/site-packages/transformers/models/bert/tokenization_bert.py:483\u001b[0m, in \u001b[0;36mWordpieceTokenizer.tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    481\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    482\u001b[0m sub_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 483\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchars\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    484\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chars)\n\u001b[1;32m    485\u001b[0m     cur_substr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_epoch(\n",
    "    net,\n",
    "    dataloader,\n",
    "    lr=0.01,\n",
    "    optimizer=None,\n",
    "    loss_fn=torch.nn.NLLLoss(),\n",
    "    epoch_size=None,\n",
    "    report_freq=200,\n",
    "):\n",
    "    # Si no s'especifica un optimitzador, utilitzem Adam\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    # Posem la xarxa en mode training. Això activa el comportament de les capes Dropout, per exemple.\n",
    "    net.train()\n",
    "\n",
    "    # Inicialitzem les variables que ens serviran per calcular la precisió\n",
    "    total_loss, acc, count, i = 0, 0, 0, 0\n",
    "\n",
    "    # Iterem sobre el dataloader\n",
    "    for labels, features in dataloader:\n",
    "\n",
    "        # Posem els gradients a zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculem la sortida de la xarxa\n",
    "        out = net(features)\n",
    "\n",
    "        # Calculem la pèrdua. Aquesta funció ja aplica la softmax a la sortida.\n",
    "        loss = loss_fn(out, labels)  # cross_entropy(out,labels)\n",
    "\n",
    "        # Propaguem la pèrdua enrere. Això farà que es calculin els gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualitzem els pesos de la xarxa. Això fa un pas d'optimització.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Actualitzem les variables per calcular la precisió.\n",
    "        total_loss += loss\n",
    "\n",
    "        # Calculem la precisió. Per fer-ho, hem de convertir la sortida de la xarxa en etiquetes.\n",
    "        # La classe amb la probabilitat més alta és la que predim com a etiqueta.\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        acc += (predicted == labels).sum()\n",
    "\n",
    "        # Actualitzem el comptador de mostres\n",
    "        count += len(labels)\n",
    "\n",
    "        # Mostrem la precisió cada report_freq mostres\n",
    "        i += 1\n",
    "        if i % report_freq == 0:\n",
    "            print(f\"{count}: acc={acc.item()/count}\")\n",
    "\n",
    "        # Si s'ha especificat epoch_size i ja hem processat aquest nombre de mostres, sortim del bucle.\n",
    "        if epoch_size and count > epoch_size:\n",
    "            break\n",
    "    return total_loss.item() / count, acc.item() / count\n",
    "\n",
    "\n",
    "# si volem entrenar la xarxa durant més èpoques, podem fer-ho amb un bucle\n",
    "def train(\n",
    "    net,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    lr=0.01,\n",
    "    epochs=10,\n",
    "    report_freq=200,\n",
    "):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            net, train_loader, optimizer=optimizer, report_freq=report_freq\n",
    "        )\n",
    "        print(f\"Train loss: {train_loss}, Train acc: {train_acc}\")\n",
    "    \n",
    "train(net, train_loader, test_loader, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3230bbc2532904",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "El model ha aconseguit una accuracy de més de `0.9` en el conjunt d'entrenament; un nombre prou acceptable tenint en compte que hem simplificat el problema per reduïr el temps d'execució del tutorial. En un cas real, utilitzaríem totes les notícies del conjunt d'entrenament i el model seria més precís."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe580202e44097",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Representació Word2Vec\n",
    "\n",
    "La representació Word2Vec és una representació molt utilitzada en el processament de llenguatge natural. Aquesta representació té en compte el context de les paraules i permet fer operacions amb les paraules. Per exemple, si restem el vector de la paraula `king` i sumem el vector de la paraula `woman`, obtindrem un vector que serà molt similar al vector de la paraula `queen`.\n",
    "\n",
    "Per generar la representació Word2Vec, utilitzarem la llibreria `gensim`. Aquesta llibreria conté molts models de representació de paraules. En aquest cas, utilitzarem el model `word2vec-google-news-300` que conté la representació Word2Vec de 3 milions de paraules i frases. \n",
    "\n",
    "> La primera vegada que s'executi aquesta cel·la, la funció `load` descarregarà el model d'1.5GB. Això pot trigar uns minuts. Un cop descarregat, el model es guardarà a la carpeta `/home/USUARI/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz` i no caldrà descarregar-lo de nou.\n",
    "> Aquesta funció retorna un objecte `KeyedVectors` que conté la representació Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12929ab110408820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:14:40.504566Z",
     "start_time": "2024-01-17T21:12:31.589189Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9fa1231614bce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ara ja podem accedir a la representació Word2Vec de cada paraula. Per exemple, per accedir a la representació de la paraula `king`, utilitzarem la funció `get_vector` de l'objecte `KeyedVectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee703eb5efc219a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:14:41.336216Z",
     "start_time": "2024-01-17T21:14:40.524698Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
       "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
       "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
       "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
       "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
       "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
       "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
       "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
       "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
       "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
       "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
       "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
       "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
       "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
       "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
       "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
       "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
       "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
       "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
       "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
       "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
       "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
       "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
       "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
       "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
       "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
       "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
       "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
       "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
       "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
       "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
       "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
       "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
       "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
       "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
       "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
       "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
       "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
       "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
       "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
       "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
       "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
       "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
       "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
       "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
       "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
       "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
       "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
       "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
       "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
       "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
       "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
       "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
       "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
       "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
       "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
       "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
       "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
       "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
       "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
       "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
       "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
       "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
       "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
       "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
       "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
       "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
       "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
       "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
       "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
       "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
       "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
       "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
       "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
       "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.get_vector('king')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1217873948a0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "També podem accedir a les paraules més similars a una paraula. Per exemple, per accedir a les paraules més similars a la paraula `king`, utilitzarem la funció `most_similar` de l'objecte `KeyedVectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdc3f5aef651db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:14:57.407515Z",
     "start_time": "2024-01-17T21:14:40.936113Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kings -> 0.7138045430183411\n",
      "queen -> 0.6510956883430481\n",
      "monarch -> 0.6413194537162781\n",
      "crown_prince -> 0.6204220056533813\n",
      "prince -> 0.6159993410110474\n",
      "sultan -> 0.5864824056625366\n",
      "ruler -> 0.5797567367553711\n",
      "princes -> 0.5646552443504333\n",
      "Prince_Paras -> 0.5432944297790527\n",
      "throne -> 0.5422105193138123\n"
     ]
    }
   ],
   "source": [
    "for w, p in w2v.most_similar('king'):\n",
    "    print(f\"{w} -> {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa38ee95af3d11",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "El més interessant de la representació Word2Vec és que els vectors tenen una estructura matemàtica que permet fer operacions amb les paraules. Per exemple, si restem el vector de la paraula `king` i sumem el vector de la paraula `woman`, obtindrem un vector que serà molt similar al vector de la paraula `queen`.\n",
    "\n",
    "$$ KING - MAN + WOMAN = QUEEN $$\n",
    "\n",
    "Per fer aquesta operació, utilitzarem la funció `most_similar` de l'objecte `KeyedVectors` i li passarem els vectors de les paraules `king`, `woman` i `man`. Aquesta funció retornarà una llista amb les paraules més similars al vector resultant. Com podem veure, la paraula més similar és `queen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79029055681603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T21:14:57.817533Z",
     "start_time": "2024-01-17T21:14:57.418430Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('queen', 0.7118193507194519)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['king', 'woman'], negative=['man'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a76b6e",
   "metadata": {},
   "source": [
    "### Classificador Word2Vec\n",
    "\n",
    "Ara crearem un classificador de notícies utilitzant la representació Word2Vec. En primer lloc haurem d'obtenir la representació Word2Vec de cada paraula per convertir el text en vectors. Després, sumarem tots els vectors per obtenir un vector per cada notícia. Aquest vector serà la representació de la notícia.\n",
    "\n",
    "Per convertir un text en un vector, utilitzarem la funció `to_w2v` que crearem a continuació. Aquesta funció rep un text i retorna un vector amb la representació Word2Vec del text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce374416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-17.0809,  11.0404,  -0.9337,  12.4042,  -6.2286,   3.0224, -10.0442,\n",
      "         -8.5156,  -5.9407,   1.1501,  -3.8471,  -8.0006, -18.2444,   4.3982,\n",
      "        -14.2061,  11.0110,  11.2352,  14.8521,  -2.5686,   2.8961, -22.3914,\n",
      "         -3.2182,   9.7872,   0.3238,  -8.6214,   4.2367, -21.9348,   5.7704,\n",
      "         -0.6942,  -1.7075,  -2.4800,   2.1805,  -7.0602, -12.3824, -11.6949,\n",
      "          8.2563, -18.9995,  11.3932,  -7.3198,   7.3370,  -6.1129,  -3.6244,\n",
      "          5.8519,   8.3060,   3.9137,  -1.8091,  -3.2730, -15.8203,  -9.6418,\n",
      "          8.9092, -16.8270,  24.5614,  -2.5387,  21.7112,   6.0571,  14.3324,\n",
      "        -17.4978, -12.2693,   1.1129, -15.9192, -12.1886,  -9.5650, -19.0873,\n",
      "         -7.7948,  -4.9111, -18.4653, -10.2332,  11.3437,  -6.0452,   5.4705,\n",
      "          3.7500,  -9.5068,   4.4747,  -0.2912,  -3.9221,   0.3543,  13.0927,\n",
      "          2.3088,   3.5300, -11.2126, -14.8031,  -2.9008,  -3.4219,  -0.3365,\n",
      "         13.8353,   7.0914,  -5.2219,  22.0132,   4.2657,   5.8488,  -0.5776,\n",
      "         -1.5022,  -5.0004, -13.3813,   4.8757,  10.3992,  -9.8992,  10.6411,\n",
      "         25.6584,  -3.4937,  -6.5989,  -1.0960,  -6.7775,   0.1842,  -6.0798,\n",
      "         13.2260,  -6.2332,   4.9711,   0.8566,   4.1002, -11.5986, -16.8590,\n",
      "         -6.4362,  -3.6979,   4.9203,  15.2933,   7.6364,  -5.8566,  -1.6903,\n",
      "         -2.3312,  12.3486,   7.5709,  -0.6597,   2.7831,  12.6196, -15.9392,\n",
      "         -9.4420,  -1.7229,   7.7839,  10.5602,  -5.9280,  -2.6489,  -6.4361,\n",
      "         -3.8383, -16.0124,   8.0287,  -3.4375,   2.8186,  22.9197,  13.0072,\n",
      "         20.2472,  -6.0054,   4.0575,  -4.7046,  -6.8406, -12.1006,  -4.0645,\n",
      "         18.0959,  -4.8794,   1.5283,   8.0677, -28.4229,  -6.3982,  -4.6095,\n",
      "         -8.2329,  -7.8615,   8.5930,  14.3553,  -2.6136,  -0.7672,   0.5814,\n",
      "          6.9687,   0.7667,   0.1969,  -1.1499,  -4.6281,  15.1071,   5.1883,\n",
      "        -10.1836,   6.9755,  -9.1791,  -8.8102,  -6.4574,  -8.9768,  -1.3514,\n",
      "         20.5255,  22.8086, -22.4160,  -2.1751,  -5.2745,   0.4971,   1.9747,\n",
      "          5.5252,  -4.8856,  -2.1867,   5.9344,  -5.4659,   5.1147,  -3.3837,\n",
      "          5.4895,  12.1746,  -4.1896, -27.1298,  -4.4509,  10.7126,   4.8896,\n",
      "         -6.0110,  -0.7719,   7.8879, -10.4668,  -9.2913,   2.1059, -19.3102,\n",
      "        -10.8101,   5.4989,  -7.4446,  -4.7968,   9.8521,  -3.9826,  14.8542,\n",
      "         16.3674,   7.4929, -11.3996,   1.8357,  -8.1945,   6.2330,  15.2261,\n",
      "         -3.4122, -16.1802,  -2.0000, -12.0552,  11.2962,   5.6537,  -0.8348,\n",
      "         -0.8463,  -6.4080,   5.8111,   2.4668,   1.0925, -14.5064,   1.1021,\n",
      "         -4.3229,  -8.5156,   1.3596,   0.2417,   1.4028,   7.4663,   8.9206,\n",
      "          7.3249,   8.0591,   7.7924,   6.9987,  27.3159,  -4.7353,   0.7053,\n",
      "          6.7754, -12.8845,  13.8699,   5.8623,  -6.8129,   5.8627,   2.7595,\n",
      "          6.3065,   9.9255,  -2.8854, -10.1693,  -7.0736,   7.9216,   2.5093,\n",
      "         -9.5866,   7.4031,  -0.9011,   9.9832,  -2.0049,  -6.3317,   0.4062,\n",
      "          0.0936,   1.1288,  -2.5539,  -2.7307,  -5.4014,  -2.8721,   1.3374,\n",
      "          0.2924,   3.5125,  -8.9189, -15.5585, -13.4326,  -9.4054,   3.7766,\n",
      "        -12.4168,  12.1424,  -1.4987,   0.1738,  -0.9734,   6.0570,  -0.8122,\n",
      "         -3.2520,  -5.7413,  -4.4579,   4.8879,  -0.8176,  -9.8232,   8.6069,\n",
      "         -3.3508, -15.2089, -10.0510,  -1.9859, -10.7878,  18.1031])\n"
     ]
    }
   ],
   "source": [
    "def to_w2v(text):\n",
    "    res = torch.zeros(300, dtype=torch.float32)\n",
    "    for word in text:\n",
    "        if word in w2v:\n",
    "            res += torch.tensor(w2v.get_vector(word))\n",
    "    return res\n",
    "\n",
    "print(to_w2v(ds_train[0][\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1b76ac",
   "metadata": {},
   "source": [
    "Igual que hem fet amb la representació BoW, utilitzarem els `DataLoaders` de PyTorch per convertir les dades en vectors Word2Vec en tensors de PyTorch. Aprofitarem el paràmetre `collate_fn` del `DataLoader` per proporcionar una funció que converteixi les dades textuals en tensors Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a6c88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2vify(batch):\n",
    "    etiquetes = torch.LongTensor([noticia[\"label\"] for noticia in batch])\n",
    "    noticies = torch.stack([to_w2v(tokenizer.tokenize(noticia[\"text\"])) for noticia in batch])\n",
    "    return etiquetes, noticies\n",
    "\n",
    "train_loader = DataLoader(ds_train, batch_size=16, collate_fn=w2vify)\n",
    "test_loader = DataLoader(ds_test, batch_size=16, collate_fn=w2vify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dffc153",
   "metadata": {},
   "source": [
    "### Model de classificació\n",
    "\n",
    "Ara crearem el model de classificació utilitzant PyTorch. Definirem un model senzill amb una capa lineal. La mida del vector d'entrada serà `300` (la mida de la representació Word2Vec) i la mida de la sortida serà el nombre de classes (4). Com que estem resolent una tasca de classificació, la funció d'activació final serà `LogSoftmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd0fd6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(300, 4),\n",
    "    torch.nn.LogSoftmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649418d1",
   "metadata": {},
   "source": [
    "Finalment, entrenarem el model utilitzant el mateix procediment que hem fet amb la representació BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55612930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: acc=0.7390625\n",
      "6400: acc=0.7721875\n",
      "9600: acc=0.7821875\n",
      "12800: acc=0.793203125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08547515706466968, 0.7995735607675906)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(net, train_loader, epoch_size=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754f4cd2c374fd4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "El resultat no es molt bo. Això és perquè el model Word2Vec que hem utilitzat no té les paraules que apareixen en el dataset. Per exemple, si busquem la paraula `covid`, veurem que no apareix en el model.\n",
    "\n",
    "Per solucionar aquest problema hauriem d'utilitzar un model Word2Vec entrenat amb les paraules del dataset. Però això és molt lent i no ho farem en aquest tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
