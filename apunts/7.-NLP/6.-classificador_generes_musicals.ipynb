{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classificador géneres de música\n",
    "\n",
    "Com a exemple d'utilització de models que treballen en audio anem a fer un classificador de gèneres de música. Per a això farem servir el dataset GTZAN, un dataset de 1000 mostres d'àudio etiquetades amb el gènere de la música."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d138c8bef4a12d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instal·lació de llibreries\n",
    "Per a poder executar aquest notebook necessitarem instal·lar les següents llibreries:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c615f3690694907"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/carlesgm/lib/python3.11/site-packages (4.37.2)\r\n",
      "Requirement already satisfied: datasets in /Users/carlesgm/lib/python3.11/site-packages (2.17.0)\r\n",
      "Requirement already satisfied: librosa in /Users/carlesgm/lib/python3.11/site-packages (0.10.1)\r\n",
      "Requirement already satisfied: soundfile in /Users/carlesgm/lib/python3.11/site-packages (0.12.1)\r\n",
      "Requirement already satisfied: torch in /Users/carlesgm/lib/python3.11/site-packages (2.2.0)\r\n",
      "Requirement already satisfied: accelerate in /Users/carlesgm/lib/python3.11/site-packages (0.27.0)\r\n",
      "Collecting evaluate\r\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\r\n",
      "Requirement already satisfied: filelock in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (0.20.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/carlesgm/lib/python3.11/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/carlesgm/lib/python3.11/site-packages (from datasets) (15.0.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/carlesgm/lib/python3.11/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/carlesgm/lib/python3.11/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/carlesgm/lib/python3.11/site-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: xxhash in /Users/carlesgm/lib/python3.11/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/carlesgm/lib/python3.11/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /Users/carlesgm/lib/python3.11/site-packages (from datasets) (2023.10.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/carlesgm/lib/python3.11/site-packages (from datasets) (3.8.5)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (1.10.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (1.2.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (5.1.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (0.59.0)\r\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (1.8.0)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (0.3.7)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (4.9.0)\r\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (0.3)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/carlesgm/lib/python3.11/site-packages (from librosa) (1.0.7)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/carlesgm/lib/python3.11/site-packages (from soundfile) (1.15.1)\r\n",
      "Requirement already satisfied: sympy in /Users/carlesgm/lib/python3.11/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/carlesgm/lib/python3.11/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/carlesgm/lib/python3.11/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: psutil in /Users/carlesgm/lib/python3.11/site-packages (from accelerate) (5.9.5)\r\n",
      "Collecting responses<0.19\r\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\r\n",
      "Requirement already satisfied: pycparser in /Users/carlesgm/lib/python3.11/site-packages (from cffi>=1.0->soundfile) (2.21)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/carlesgm/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/carlesgm/lib/python3.11/site-packages (from aiohttp->datasets) (3.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/carlesgm/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/carlesgm/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/carlesgm/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/carlesgm/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/carlesgm/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /Users/carlesgm/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.42.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/carlesgm/lib/python3.11/site-packages (from pooch>=1.0->librosa) (3.5.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/carlesgm/lib/python3.11/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/carlesgm/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/carlesgm/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/carlesgm/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/carlesgm/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/carlesgm/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/carlesgm/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/carlesgm/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/carlesgm/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/carlesgm/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Installing collected packages: responses, evaluate\r\n",
      "Successfully installed evaluate-0.4.1 responses-0.18.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets librosa soundfile torch accelerate evaluate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:00:08.434888Z",
     "start_time": "2024-02-14T06:59:41.880276Z"
    }
   },
   "id": "2f002a03e6f0e117",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carreguem el dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f506289975ff0d80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "gtzan = load_dataset(\"marsyas/gtzan\", \"all\", trust_remote_code=True)\n",
    "gtzan"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b232bb10c0394142",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com podem veure, el dataset consta de 99 mostres d'àudio etiquetades amb el gènere de la música."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7926aead087f9ec4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Els audios estan en format de 22050 Hz, per a poder-los processar amb el model necessitarem convertir-los a un format que pugui ser processat pel model (normalment 16kHz). Això ho farem amb la classe `Audio` de la llibreria datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "588dcd3a3af20280"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "gtzan = gtzan.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eda1d3f9717dbc08",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creació del dataset de `test`\n",
    "\n",
    "Per a poder avaluar el model necessitarem un dataset de test. Per a això dividirem el dataset en dos parts, una per a entrenar el model i una altra per a avaluar-lo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "403ed153c7d5afba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gtzan = gtzan[\"train\"].train_test_split(seed=42, shuffle=True, test_size=0.1)\n",
    "gtzan"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac796c9364dc1882",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vegada separat el dataset en dos parts, el dataset de test contindrà 100 mostres d'àudio.\n",
    "\n",
    "A continuació mostrarem una mostra del dataset de test."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcf1f1bf669ab51d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gtzan['train'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a6af0527a74e424",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "De cada mostra del dataset de test podem veure que tenim les següents dades:\n",
    "- `audio`: El path a l'arxiu d'àudio.\n",
    "- `array`: L'àudio en format d'array. El valor de cada element de l'array representa l'amplitud de l'ona en un instant de temps. Com el valor de samplig és de 16000 Hz, aquest array tindrà 16000 elements per segon.\n",
    "- `genre`: El gènere de la música com a enter. Podem utilitzar el métode `int2str()` del `feature` _genre()_ per a obtenir el gènere en format llegible."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "467261b3fee3498c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "int2str = gtzan[\"train\"].features[\"genre\"].int2str\n",
    "int2str(gtzan['train'][0]['genre'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fe2912b123d91a3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testeig del model sense entrenar\n",
    "\n",
    "Abans de començar a entrenar el model, testejarem el model sense entrenar per a veure com es comporta. Utilitzarem el model `distilhubert`, un model pre-entrenat per a classificar audio i lleuger de refinar.\n",
    "\n",
    "Per a utilitzar el model farem servir la classe `pipeline` de la llibreria transformers."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ad7dcda21efd670"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['classifier.bias', 'classifier.weight', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"audio-classification\", model=\"ntu-spml/distilhubert\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T00:11:29.890682Z",
     "start_time": "2024-02-13T00:11:27.980985Z"
    }
   },
   "id": "b68cd849ec18fc4c",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.5038169026374817, 'label': 'LABEL_1'},\n {'score': 0.4961830973625183, 'label': 'LABEL_0'}]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(gtzan['train'][0]['audio'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T00:11:45.733054Z",
     "start_time": "2024-02-13T00:11:31.912228Z"
    }
   },
   "id": "9ed1ca5c21577c67",
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "Anem a calcular la precisió del model sense entrenar. Per a això farem servir el dataset de test.\n",
    "\n",
    "El primer que farem serà calcular les prediccions del model per a cada mostra del dataset de test.\n",
    "\n",
    "A continuació mostrarem les prediccions del model per a la primera mostra del dataset de test."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5660a6feff1cbc09"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgtzan\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m      2\u001B[0m predictions[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[0;32mIn[44], line 1\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[0;32m----> 1\u001B[0m predictions \u001B[38;5;241m=\u001B[39m [\u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m gtzan[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m      2\u001B[0m predictions[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/pipelines/audio_classification.py:136\u001B[0m, in \u001B[0;36mAudioClassificationPipeline.__call__\u001B[0;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    105\u001B[0m     inputs: Union[np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;28mbytes\u001B[39m, \u001B[38;5;28mstr\u001B[39m],\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    107\u001B[0m ):\n\u001B[1;32m    108\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;124;03m    Classify the sequence(s) given as inputs. See the [`AutomaticSpeechRecognitionPipeline`] documentation for more\u001B[39;00m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;124;03m    information.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;124;03m        - **score** (`float`) -- The corresponding probability.\u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/pipelines/base.py:1162\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[1;32m   1155\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[1;32m   1156\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1159\u001B[0m         )\n\u001B[1;32m   1160\u001B[0m     )\n\u001B[1;32m   1161\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/pipelines/base.py:1169\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[1;32m   1168\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[0;32m-> 1169\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1170\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[1;32m   1171\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/pipelines/base.py:1068\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[0;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[1;32m   1066\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[1;32m   1067\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m-> 1068\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1069\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/pipelines/audio_classification.py:203\u001B[0m, in \u001B[0;36mAudioClassificationPipeline._forward\u001B[0;34m(self, model_inputs)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, model_inputs):\n\u001B[0;32m--> 203\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_outputs\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py:1349\u001B[0m, in \u001B[0;36mHubertForSequenceClassification.forward\u001B[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001B[0m\n\u001B[1;32m   1346\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   1347\u001B[0m output_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_weighted_layer_sum \u001B[38;5;28;01melse\u001B[39;00m output_hidden_states\n\u001B[0;32m-> 1349\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhubert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1350\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1352\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1353\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1357\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_weighted_layer_sum:\n\u001B[1;32m   1358\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m outputs[_HIDDEN_STATES_START_POSITION]\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py:1091\u001B[0m, in \u001B[0;36mHubertModel.forward\u001B[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1088\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_projection(extract_features)\n\u001B[1;32m   1089\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mask_hidden_states(hidden_states, mask_time_indices\u001B[38;5;241m=\u001B[39mmask_time_indices)\n\u001B[0;32m-> 1091\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1092\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1093\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1094\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1095\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1096\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1097\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py:713\u001B[0m, in \u001B[0;36mHubertEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    708\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m attention_mask \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mfinfo(hidden_states\u001B[38;5;241m.\u001B[39mdtype)\u001B[38;5;241m.\u001B[39mmin\n\u001B[1;32m    709\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m attention_mask\u001B[38;5;241m.\u001B[39mexpand(\n\u001B[1;32m    710\u001B[0m         attention_mask\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m, attention_mask\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], attention_mask\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    711\u001B[0m     )\n\u001B[0;32m--> 713\u001B[0m position_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpos_conv_embed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    714\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m position_embeddings\n\u001B[1;32m    715\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(hidden_states)\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py:294\u001B[0m, in \u001B[0;36mHubertPositionalConvEmbedding.forward\u001B[0;34m(self, hidden_states)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states):\n\u001B[1;32m    292\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m hidden_states\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m--> 294\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    295\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding(hidden_states)\n\u001B[1;32m    296\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(hidden_states)\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/conv.py:310\u001B[0m, in \u001B[0;36mConv1d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/torch/nn/modules/conv.py:306\u001B[0m, in \u001B[0;36mConv1d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv1d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    304\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    305\u001B[0m                     _single(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 306\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    307\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "predictions = [classifier(sample['audio']) for sample in gtzan['test']]\n",
    "predictions[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T00:15:31.797991Z",
     "start_time": "2024-02-13T00:12:55.278581Z"
    }
   },
   "id": "9996ed6fa22fb1b3",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "Un cop tenim les prediccions del model, les compararem amb les etiquetes reals per a calcular la precisió del model.\n",
    "\n",
    "A continuació mostrarem la precisió del model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc6e997fc93f4610"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [f\"LABEL_{sample['genre']}\" for sample in gtzan['test']]\n",
    "y_pred = [prediction[0]['label'] for prediction in predictions]\n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-13T00:15:31.794357Z"
    }
   },
   "id": "9a761cfbb31d102a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessament del dataset\n",
    "\n",
    "Com podem veure, el model sense entrenar té una precisió del 10%, molt poc. Això és degut a que el model no ha estat entrenat amb el dataset GTZAN.\n",
    "\n",
    "Per a entrenar el model farem servir la classe `Trainer` de la llibreria transformers. Aquesta classe ens permet entrenar models de manera senzilla i eficient.\n",
    "\n",
    "Mentre que amb altres models necessitem un model i un `Tokenizer` en aquest cas farem servir un `model` i un feature_extractor`. Aquesta classe ens permetrà processar les mostres d'àudio per a convertir-les en un format que pugui ser processat pel model.\n",
    "\n",
    "A continuació crearem el `feature_extractor` i que farem servir per a entrenar el model. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a14e6a7a8e02ee7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "model_id = \"ntu-spml/distilhubert\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id, do_normalize=True, return_attention_mask=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e4f0971ce1cbbcc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuació processarrem les mostres d'àudio, convertint-les en un format que pugui ser processat pel model. En el nostre cas, retallarem les mostres d'àudio a 30 segons utilitzant les opcions `max_length` i `padding` del `feature_extractor` i llevarem les dades que no ens interessen del dataset amb el mètode `remove_columns`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db7030bef8f21526"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_duration = 30.0\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=feature_extractor.sampling_rate,\n",
    "        max_length=int(feature_extractor.sampling_rate * max_duration),\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T07:51:40.861686Z",
     "start_time": "2024-02-13T07:51:40.845697Z"
    }
   },
   "id": "de6d0f23e0c7536d",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/899 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6758a7662774ff4bc9b6ea902a2b7ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'feature_extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m gtzan_encoded \u001B[38;5;241m=\u001B[39m \u001B[43mgtzan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreprocess_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfile\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m gtzan_encoded\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/datasets/dataset_dict.py:868\u001B[0m, in \u001B[0;36mDatasetDict.map\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001B[0m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    866\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[1;32m    867\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[0;32m--> 868\u001B[0m     \u001B[43m{\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    873\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m            \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m    890\u001B[0m )\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/datasets/dataset_dict.py:869\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    866\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[1;32m    867\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[1;32m    868\u001B[0m     {\n\u001B[0;32m--> 869\u001B[0m         k: \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    873\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m            \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    888\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    889\u001B[0m     }\n\u001B[1;32m    890\u001B[0m )\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/datasets/arrow_dataset.py:593\u001B[0m, in \u001B[0;36mtransmit_tasks.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    591\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    592\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 593\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    594\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/datasets/arrow_dataset.py:558\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    551\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[1;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[1;32m    555\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[1;32m    556\u001B[0m }\n\u001B[1;32m    557\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 558\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    559\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    560\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/datasets/arrow_dataset.py:3105\u001B[0m, in \u001B[0;36mDataset.map\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[1;32m   3099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3100\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m hf_tqdm(\n\u001B[1;32m   3101\u001B[0m         unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m examples\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3102\u001B[0m         total\u001B[38;5;241m=\u001B[39mpbar_total,\n\u001B[1;32m   3103\u001B[0m         desc\u001B[38;5;241m=\u001B[39mdesc \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3104\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[0;32m-> 3105\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m rank, done, content \u001B[38;5;129;01min\u001B[39;00m Dataset\u001B[38;5;241m.\u001B[39m_map_single(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdataset_kwargs):\n\u001B[1;32m   3106\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[1;32m   3107\u001B[0m                 shards_done \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/datasets/arrow_dataset.py:3482\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[1;32m   3478\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[1;32m   3479\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(shard\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[1;32m   3480\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[1;32m   3481\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3482\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3485\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_same_num_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mshard\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_indexes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3486\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3487\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3488\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[1;32m   3489\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[1;32m   3490\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3491\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/datasets/arrow_dataset.py:3361\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[1;32m   3359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[1;32m   3360\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[0;32m-> 3361\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43madditional_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[1;32m   3363\u001B[0m     processed_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   3364\u001B[0m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mkeys_to_format\n\u001B[1;32m   3365\u001B[0m     }\n",
      "Cell \u001B[0;32mIn[46], line 6\u001B[0m, in \u001B[0;36mpreprocess_function\u001B[0;34m(examples)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess_function\u001B[39m(examples):\n\u001B[1;32m      5\u001B[0m     audio_arrays \u001B[38;5;241m=\u001B[39m [x[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m examples[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maudio\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\n\u001B[0;32m----> 6\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[43mfeature_extractor\u001B[49m(\n\u001B[1;32m      7\u001B[0m         audio_arrays,\n\u001B[1;32m      8\u001B[0m         sampling_rate\u001B[38;5;241m=\u001B[39mfeature_extractor\u001B[38;5;241m.\u001B[39msampling_rate,\n\u001B[1;32m      9\u001B[0m         max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(feature_extractor\u001B[38;5;241m.\u001B[39msampling_rate \u001B[38;5;241m*\u001B[39m max_duration),\n\u001B[1;32m     10\u001B[0m         truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     11\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     12\u001B[0m     )\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inputs\n",
      "\u001B[0;31mNameError\u001B[0m: name 'feature_extractor' is not defined"
     ]
    }
   ],
   "source": [
    "gtzan_encoded = gtzan.map(\n",
    "    preprocess_function,\n",
    "    remove_columns=[\"audio\", \"file\"],\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    num_proc=1,\n",
    ")\n",
    "gtzan_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T07:51:53.611194Z",
     "start_time": "2024-02-13T07:51:44.033842Z"
    }
   },
   "id": "bde132d87138c441",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "Renomenarem la columna `genre` a `label` per a que el `Trainer` pugui identificar-la com a columna de labels."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1835cbe56384b01f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gtzan_encoded = gtzan_encoded.rename_column(\"genre\", \"label\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14fc39377d331a7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per últim abans de començar a entrenar el model, crearem un diccionari en les correspondències entre els noms dels gèneres i els seus valors enters, per a que el `Trainer` pugui identificar-los i permetre un canvi ràpid entre els dos formats."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e89d89d98eec1d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    str(i): int2str(i)\n",
    "    for i in range(len(gtzan_encoded[\"train\"].features[\"label\"].names))\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "id2label[\"7\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc09f0a71fe603bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrenament del model\n",
    "\n",
    "A continuació crearem el model que anem a entrenar."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e236cf5e07b00380"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id, num_labels=len(id2label)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f80cbc9a41f43456"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuació crearem els `TrainerArguments`, que ens permetrà configurar el `Trainer` per a entrenar el model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58a069a61138f2e6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "--load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.EPOCH\n- Save strategy: IntervalStrategy.STEPS",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TrainingArguments\n\u001B[0;32m----> 3\u001B[0m training_args \u001B[38;5;241m=\u001B[39m \u001B[43mTrainingArguments\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevaluation_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mepoch\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2e-5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mper_device_train_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mper_device_eval_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_train_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mload_best_model_at_end\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_for_best_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maccuracy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<string>:121\u001B[0m, in \u001B[0;36m__init__\u001B[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha)\u001B[0m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/training_args.py:1378\u001B[0m, in \u001B[0;36mTrainingArguments.__post_init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_best_model_at_end:\n\u001B[1;32m   1377\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_strategy \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_strategy:\n\u001B[0;32m-> 1378\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1379\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--load_best_model_at_end requires the save and eval strategy to match, but found\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m- Evaluation \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1380\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrategy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_strategy\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m- Save strategy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_strategy\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1381\u001B[0m         )\n\u001B[1;32m   1382\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_strategy \u001B[38;5;241m==\u001B[39m IntervalStrategy\u001B[38;5;241m.\u001B[39mSTEPS \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_steps \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meval_steps \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1383\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meval_steps \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_steps \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[0;31mValueError\u001B[0m: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.EPOCH\n- Save strategy: IntervalStrategy.STEPS"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T22:28:31.604601Z",
     "start_time": "2024-02-13T22:28:30.481869Z"
    }
   },
   "id": "6577d17994a056d9",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuació crearem el `Trainer`, classe que s'encarregarà de fer l'entrenament del model, i l'executarem."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "273432635115fedc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=gtzan_encoded[\"train\"],\n",
    "    eval_dataset=gtzan_encoded[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=accuracy_score,\n",
    ")\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e45b05bfcc58179a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testeig del model entrenat\n",
    "\n",
    "Un cop entrenat el model, testejarem el model amb el dataset de test per a veure com es comporta.\n",
    "\n",
    "A continuació mostrarem la precisió del model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bee703c6a9c20037"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trainer: evaluation requires an eval_dataset.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/trainer.py:3091\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3088\u001B[0m \u001B[38;5;66;03m# memory metrics - must set up as early as possible\u001B[39;00m\n\u001B[1;32m   3089\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory_tracker\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m-> 3091\u001B[0m eval_dataloader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_eval_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3092\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3094\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n",
      "File \u001B[0;32m~/lib/python3.11/site-packages/transformers/trainer.py:846\u001B[0m, in \u001B[0;36mTrainer.get_eval_dataloader\u001B[0;34m(self, eval_dataset)\u001B[0m\n\u001B[1;32m    835\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    836\u001B[0m \u001B[38;5;124;03mReturns the evaluation [`~torch.utils.data.DataLoader`].\u001B[39;00m\n\u001B[1;32m    837\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    843\u001B[0m \u001B[38;5;124;03m        by the `model.forward()` method are automatically removed. It must implement `__len__`.\u001B[39;00m\n\u001B[1;32m    844\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    845\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m eval_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meval_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 846\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrainer: evaluation requires an eval_dataset.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    847\u001B[0m eval_dataset \u001B[38;5;241m=\u001B[39m eval_dataset \u001B[38;5;28;01mif\u001B[39;00m eval_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meval_dataset\n\u001B[1;32m    848\u001B[0m data_collator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_collator\n",
      "\u001B[0;31mValueError\u001B[0m: Trainer: evaluation requires an eval_dataset."
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T23:07:37.353185Z",
     "start_time": "2024-02-13T23:07:37.135160Z"
    }
   },
   "id": "2516ae0ab62a87c4",
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classificació d'una cançó\n",
    "\n",
    "Un cop creat el pipeline podem fer servir el mètode `classifier` per a classificar una cançó. Aquest mètode rep com a paràmetre el path a la cançó que volem classificar i retorna el gènere de la cançó.\n",
    "\n",
    "Previament necessitarem música per a poder-la classificar. A continuació teniu alguns enllaços de música lliure per a poder-la descarregar i fer servir en aquest notebook:\n",
    "\n",
    "- [Música clàssica](https://freemusicarchive.org/genre/Classical)\n",
    "- [Música electrònica](https://freemusicarchive.org/genre/Electronic)\n",
    "- [Música pop](https://freemusicarchive.org/genre/Pop)\n",
    "- [Música rock](https://freemusicarchive.org/genre/Rock)\n",
    "- [Música jazz](https://freemusicarchive.org/genre/Jazz)\n",
    "\n",
    "També proporcionem enllaços directes que a alguns `samples` que podeu descarregar en la llibreria requests:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f108abc5cfedd69b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "musica = [\n",
    "    \"https://archive.org/download/cd_the-very-best-of-frank-sinatra_frank-sinatra-frank-nancy-sinatra/disc1/01.07.%20Frank%20Sinatra%20-%20Fly%20Me%20to%20the%20Moon%20%28In%20Other%20Words%29_sample.mp3\",\n",
    "    \"https://archive.org/download/cd_random-access-memories_daft-punk/disc1/05.%20Daft%20Punk%20-%20Instant%20Crush_sample.mp3\",\n",
    "    \"https://freemusicarchive.org/file/music/no_curator/Blue_Dot_Sessions/Organisms/Organisms_-_Blue_Dot_Sessions.mp3\",\n",
    "    \"https://archive.org/download/cd_meteora_linkin-park/disc1/03.%20Linkin%20Park%20-%20Somewhere%20I%20Belong_sample.mp3\"\n",
    "    \"https://ia800101.us.archive.org/21/items/cd_debbie-does-dallas_andrew-sherman/disc1/02.%20Andrew%20Sherman%20-%20Overture_sample.mp3\",\n",
    "    \"https://archive.org/download/cd_greatest-hits_journey/Journey%20%281988%29%20-%20Journey%27s%20Greatest%20Hits%20%5BFLAC%5D/02%20-%20Don%27t%20Stop%20Believin%27_sample.mp3\",\n",
    "    \"https://archive.org/download/cd_generator_bad-religion/disc1/01.%20Bad%20Religion%20-%20Generator_sample.mp3\",\n",
    "    \"https://archive.org/download/geniesduclassique_vol1no12/1-09%20Concerto%20Brandeburghese%20No.3%20-%20Adagio.mp3\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d849a9cd9cb9a2e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result = classifier(musica[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b3a829b89de65e4",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
